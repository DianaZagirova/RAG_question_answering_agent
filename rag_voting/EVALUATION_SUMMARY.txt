================================================================================
QA EVALUATION SUMMARY: Full-Text vs RAG Approaches
================================================================================

DATASET OVERVIEW:
- Full-text results: 18,166 papers
- RAG results: 15,493 papers
- Standard validation set: 5 papers (30 questions)
- Extended validation set: 104 papers (306 questions for fulltext, 258 for RAG)

================================================================================
PERFORMANCE COMPARISON
================================================================================

STANDARD VALIDATION SET (5 papers):
┌─────────────────────────┬──────────────┬──────────────┐
│ Method                  │ Accuracy     │ Correct/Total│
├─────────────────────────┼──────────────┼──────────────┤
│ Full-text               │ 66.67%       │ 20/30        │
│ RAG                     │ 58.33%       │ 7/12         │
└─────────────────────────┴──────────────┴──────────────┘

EXTENDED VALIDATION SET (104 papers):
┌─────────────────────────┬──────────────┬──────────────┐
│ Method                  │ Accuracy     │ Correct/Total│
├─────────────────────────┼──────────────┼──────────────┤
│ Full-text               │ 67.32%       │ 206/306      │
│ RAG                     │ 69.77%       │ 180/258      │
└─────────────────────────┴──────────────┴──────────────┘

KEY OBSERVATION: RAG performs slightly better on the extended set, while 
full-text has broader coverage.

================================================================================
COMBINATION STRATEGIES PERFORMANCE
================================================================================

STANDARD VALIDATION SET:
┌────────────────────────────┬──────────────┬──────────────┐
│ Strategy                   │ Accuracy     │ Correct/Total│
├────────────────────────────┼──────────────┼──────────────┤
│ 1. RAG Yes Override        │ 75.00% ★     │ 9/12         │
│ 2. Optimistic              │ 75.00% ★     │ 9/12         │
│ 3. Question-Specific       │ 74.07%       │ 20/27        │
│ 4. Agree Only              │ 70.00%       │ 7/10         │
│ 5. Full-text Only          │ 66.67%       │ 20/30        │
│ 6. Confidence-Based        │ 66.67%       │ 20/30        │
│ 7. RAG Only                │ 58.33%       │ 7/12         │
│ 8. RAG No Override         │ 58.33%       │ 7/12         │
│ 9. Conservative            │ 58.33%       │ 7/12         │
└────────────────────────────┴──────────────┴──────────────┘

EXTENDED VALIDATION SET:
┌────────────────────────────┬──────────────┬──────────────┐
│ Strategy                   │ Accuracy     │ Correct/Total│
├────────────────────────────┼──────────────┼──────────────┤
│ 1. Agree Only              │ 76.32% ★     │ 174/228      │
│ 2. Conservative            │ 70.54%       │ 182/258      │
│ 3. RAG No Override         │ 70.16%       │ 181/258      │
│ 4. RAG Only                │ 69.77%       │ 180/258      │
│ 5. Optimistic              │ 69.38%       │ 179/258      │
│ 6. RAG Yes Override        │ 68.99%       │ 178/258      │
│ 7. Question-Specific       │ 68.61%       │ 188/274      │
│ 8. Full-text Only          │ 67.32%       │ 206/306      │
│ 9. Confidence-Based        │ 67.32%       │ 206/306      │
└────────────────────────────┴──────────────┴──────────────┘

================================================================================
STRATEGY DESCRIPTIONS
================================================================================

1. RAG YES OVERRIDE (Recommended for Standard Set - 75.00%)
   → Use full-text answers as baseline
   → When RAG says "Yes", trust RAG's answer
   → Rationale: Leverages full-text's broad coverage while trusting RAG's 
     precision for positive findings

2. AGREE ONLY (Best for Extended Set - 76.32%)
   → Only provide answer when both methods agree
   → Otherwise abstain
   → Rationale: High precision by requiring consensus
   → Trade-off: Lower coverage (228 vs 306 questions)

3. OPTIMISTIC (75.00% on Standard Set)
   → Answer "Yes" if either method says "Yes"
   → Otherwise answer "No"
   → Rationale: Maximizes recall for positive findings

4. QUESTION-SPECIFIC (74.07% on Standard Set)
   → Use the best-performing method for each question type
   → Rationale: Different questions benefit from different approaches

5. CONSERVATIVE (70.54% on Extended Set)
   → Answer "Yes" only if both methods agree on "Yes"
   → Otherwise answer "No"
   → Rationale: High precision for positive claims

6. CONFIDENCE-BASED
   → Use RAG if confidence > 0.9, otherwise use full-text
   → Rationale: Trust RAG when it's highly confident

================================================================================
RECOMMENDED STRATEGY: RAG YES OVERRIDE
================================================================================

IMPLEMENTATION:
```python
def combined_answer(fulltext_answer, rag_answer):
    """
    Combine full-text and RAG answers using RAG Yes Override strategy.
    
    Args:
        fulltext_answer: Answer from full-text analysis (Yes/No)
        rag_answer: Answer from RAG analysis (Yes/No)
    
    Returns:
        Combined answer (Yes/No)
    """
    # If RAG says Yes, trust it (RAG is precise for positive findings)
    if rag_answer == "Yes":
        return "Yes"
    
    # Otherwise, use full-text answer (broader coverage)
    return fulltext_answer
```

WHY THIS WORKS:
✓ Full-text provides comprehensive coverage of the entire document
✓ RAG is precise when it identifies positive evidence
✓ Combines strengths: full-text's recall + RAG's precision
✓ 8.33% improvement over full-text alone on standard set
✓ Simple to implement and understand

WHEN TO USE ALTERNATIVES:
• Use "Agree Only" when precision is critical and you can afford to skip 
  ambiguous cases (76.32% accuracy but lower coverage)
• Use "Question-Specific" when you have enough data to determine which 
  method works best for each question type (74.07% accuracy)
• Use "Conservative" when false positives are more costly than false 
  negatives (70.54% on extended set)

================================================================================
PER-QUESTION PERFORMANCE INSIGHTS
================================================================================

EXTENDED VALIDATION SET BREAKDOWN:

Question Type                              Full-text    RAG
─────────────────────────────────────────────────────────────────
Aging Biomarker                            7.8%         7.0%
  → Both struggle with this question type
  → May need different approach or better training

Aging Cannot Be Reversed                   96.1%        97.7%
  → Both excel at this question
  → High agreement expected

Birds Lifespan Explanation                 70.6%        76.7%
  → RAG performs better (+6.1%)
  → Consider RAG preference for this question

Calorie Restriction Explanation            70.6%        72.1%
  → Similar performance
  → Either method acceptable

Large Animals Lifespan Explanation         74.5%        81.4%
  → RAG performs better (+6.9%)
  → Consider RAG preference for this question

Naked Mole Rat Explanation                 84.3%        83.7%
  → Both perform well and similarly
  → Either method acceptable

================================================================================
ACTIONABLE RECOMMENDATIONS
================================================================================

1. IMMEDIATE IMPLEMENTATION:
   Deploy "RAG Yes Override" strategy for production use
   - Expected accuracy: 75% (standard set) / 69% (extended set)
   - Simple logic, easy to maintain
   - Good balance of precision and recall

2. QUESTION-SPECIFIC OPTIMIZATION:
   For specific question types, use the better performer:
   - Birds lifespan: Prefer RAG (76.7% vs 70.6%)
   - Large animals lifespan: Prefer RAG (81.4% vs 74.5%)
   - Aging biomarker: Both struggle - needs investigation

3. CONFIDENCE THRESHOLDING:
   When RAG confidence > 0.9, trust RAG regardless of full-text
   - Leverages RAG's high-confidence predictions
   - Falls back to full-text for uncertain cases

4. FUTURE IMPROVEMENTS:
   - Investigate why both methods struggle with "aging biomarker" (7-8%)
   - Consider ensemble methods with learned weights per question type
   - Collect more validation data for better strategy tuning
   - Implement confidence calibration for RAG predictions

================================================================================
CONCLUSION
================================================================================

The analysis demonstrates that combining full-text and RAG approaches yields
better results than either method alone. The "RAG Yes Override" strategy
achieves 75% accuracy on the standard validation set (8.33% improvement over
full-text alone), while the "Agree Only" strategy achieves 76.32% on the
extended set with high precision.

Key takeaway: Different strategies excel in different scenarios. Choose based
on your priorities:
- Precision → "Agree Only" (76.32%)
- Balance → "RAG Yes Override" (75.00%)
- Coverage → "Full-text Only" (67.32%)

Generated by: qa_analyzer.py
Date: 2025-10-22
